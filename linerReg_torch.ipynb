{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习的框架实现线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "from torch.utils import data\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2                                         \n",
    "features,labels=d2l.synthetic_data(true_w,true_b,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.2049,  0.0834],\n",
       "         [-0.9317, -0.1080],\n",
       "         [-1.2916,  1.2821],\n",
       "         [ 0.4161, -1.6854],\n",
       "         [-0.5365,  0.7300],\n",
       "         [ 0.1634,  1.6651],\n",
       "         [-1.3858,  1.6180],\n",
       "         [-0.2503, -0.3789],\n",
       "         [ 0.0106, -1.4347],\n",
       "         [-1.7418,  0.4762]]),\n",
       " tensor([[ 3.5058],\n",
       "         [ 2.6856],\n",
       "         [-2.7317],\n",
       "         [10.7582],\n",
       "         [ 0.6456],\n",
       "         [-1.1279],\n",
       "         [-4.0749],\n",
       "         [ 4.9905],\n",
       "         [ 9.1132],\n",
       "         [-0.9197]])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_array(data_arrays,batch_size,is_train=True):\n",
    "    #构造一个pytorch数据迭代器\n",
    "    dataset=data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset,batch_size,shuffle=is_train)\n",
    "\n",
    "batch_size =10\n",
    "data_iter=load_array((features,labels),batch_size)\n",
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "net =nn.Sequential(nn.Linear(2,1))\n",
    "net[0].weight.data.normal_(0,0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=torch.optim.SGD(net.parameters(),lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,loss0.000097\n",
      "epoch2,loss0.000097\n",
      "epoch3,loss0.000096\n",
      "epoch4,loss0.000097\n",
      "epoch5,loss0.000097\n",
      "epoch6,loss0.000097\n",
      "epoch7,loss0.000097\n",
      "epoch8,loss0.000097\n",
      "epoch9,loss0.000097\n",
      "epoch10,loss0.000096\n"
     ]
    }
   ],
   "source": [
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    "    for X,y in data_iter:\n",
    "        l= loss(net(X),y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l=loss(net(features),labels)\n",
    "    print(f'epoch{epoch+1},loss{l:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
